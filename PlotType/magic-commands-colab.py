# =============================================================================
# MAGIC COMMANDS - JupyterLab ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å†…ã§ä½¿ç”¨å¯èƒ½ãªãƒã‚¸ãƒƒã‚¯ã‚³ãƒãƒ³ãƒ‰
# =============================================================================

from IPython.core.magic import Magics, magics_class, line_magic, cell_magic
from IPython.core.display import display, HTML, JSON
import requests
import json
import os
import time
from typing import Dict, List, Optional, Any
import subprocess
import asyncio
import aiohttp

@magics_class
class AIDevMagics(Magics):
    """AI Development Extension Magic Commands"""
    
    def __init__(self, shell=None):
        super().__init__(shell)
        self.colab_nodes: Dict[str, str] = {}
        self.active_jobs: Dict[str, Dict] = {}
        self.claude_session: List[Dict] = []
        
    # =========================================================================
    # COLAB MAGIC COMMANDS
    # =========================================================================
    
    @line_magic
    def colab_connect(self, line: str) -> None:
        """
        Colab ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«æ¥ç¶š
        ä½¿ç”¨ä¾‹: %colab_connect https://abc123.ngrok.io
        """
        url = line.strip()
        if not url:
            print("âŒ Usage: %colab_connect <ngrok_url>")
            return
            
        try:
            # Health check
            response = requests.get(f"{url}/health", timeout=10)
            response.raise_for_status()
            
            # Node info å–å¾—
            info_response = requests.get(f"{url}/info", timeout=10)
            node_info = info_response.json()
            
            node_id = f"colab_{int(time.time())}"
            self.colab_nodes[node_id] = url
            
            print(f"âœ… Colabæ¥ç¶šæˆåŠŸ!")
            print(f"   Node ID: {node_id}")
            print(f"   GPU: {node_info.get('gpu', 'N/A')}")
            print(f"   Runtime: {node_info.get('runtime', 'N/A')}")
            
            # JupyterLab Extension ã«é€šçŸ¥
            self._notify_extension('colab_connected', {
                'node_id': node_id,
                'url': url,
                'info': node_info
            })
            
        except Exception as e:
            print(f"âŒ Colabæ¥ç¶šå¤±æ•—: {str(e)}")
    
    @line_magic
    def colab_status(self, line: str) -> None:
        """
        æ¥ç¶šä¸­ã® Colab ãƒãƒ¼ãƒ‰çŠ¶æ³ã‚’è¡¨ç¤º
        ä½¿ç”¨ä¾‹: %colab_status
        """
        if not self.colab_nodes:
            print("ğŸ“­ æ¥ç¶šä¸­ã®Colabãƒãƒ¼ãƒ‰ã¯ã‚ã‚Šã¾ã›ã‚“")
            return
        
        print(f"ğŸ–¥ï¸  æ¥ç¶šä¸­ã®Colabãƒãƒ¼ãƒ‰ ({len(self.colab_nodes)}å€‹):")
        print("-" * 60)
        
        for node_id, url in self.colab_nodes.items():
            try:
                response = requests.get(f"{url}/resources", timeout=5)
                resources = response.json()
                
                gpu = resources.get('gpu', [{}])[0]
                memory = resources.get('memory', {})
                
                print(f"Node: {node_id}")
                print(f"  URL: {url}")
                print(f"  GPU: {gpu.get('name', 'N/A')} ({gpu.get('utilization', 0):.1f}%)")
                print(f"  Memory: {memory.get('percent', 0):.1f}% used")
                print()
                
            except Exception as e:
                print(f"Node: {node_id} - âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                print()
    
    @cell_magic
    def colab_train(self, line: str, cell: str) -> None:
        """
        Colab ã‚¯ãƒ©ã‚¹ã‚¿ã§åˆ†æ•£å­¦ç¿’å®Ÿè¡Œ
        ä½¿ç”¨ä¾‹:
        %%colab_train --nodes 2 --epochs 10
        import torch
        # å­¦ç¿’ã‚³ãƒ¼ãƒ‰
        """
        args = self._parse_args(line)
        node_count = int(args.get('nodes', 1))
        epochs = int(args.get('epochs', 10))
        
        if not self.colab_nodes:
            print("âŒ Colabãƒãƒ¼ãƒ‰ãŒæ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        available_nodes = list(self.colab_nodes.items())[:node_count]
        
        if len(available_nodes) < node_count:
            print(f"âš ï¸  è¦æ±‚ãƒãƒ¼ãƒ‰æ•°: {node_count}, åˆ©ç”¨å¯èƒ½: {len(available_nodes)}")
        
        job_id = f"job_{int(time.time())}"
        
        print(f"ğŸš€ åˆ†æ•£å­¦ç¿’é–‹å§‹")
        print(f"   Job ID: {job_id}")
        print(f"   ãƒãƒ¼ãƒ‰æ•°: {len(available_nodes)}")
        print(f"   ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
        print("-" * 40)
        
        # å„ãƒãƒ¼ãƒ‰ã«ã‚¿ã‚¹ã‚¯é…å¸ƒ
        results = []
        for idx, (node_id, url) in enumerate(available_nodes):
            task_config = {
                'job_id': job_id,
                'node_id': node_id,
                'node_index': idx,
                'total_nodes': len(available_nodes),
                'epochs': epochs,
                'code': cell
            }
            
            try:
                response = requests.post(
                    f"{url}/train", 
                    json=task_config,
                    timeout=30
                )
                response.raise_for_status()
                result = response.json()
                
                print(f"âœ… Node {node_id}: å­¦ç¿’é–‹å§‹")
                results.append(result)
                
            except Exception as e:
                print(f"âŒ Node {node_id}: å¤±æ•— - {str(e)}")
        
        if results:
            self.active_jobs[job_id] = {
                'nodes': available_nodes,
                'start_time': time.time(),
                'status': 'running'
            }
            print(f"\nğŸ’¡ é€²æ—ç¢ºèª: %colab_job_status {job_id}")
    
    @line_magic
    def colab_job_status(self, line: str) -> None:
        """
        å­¦ç¿’ã‚¸ãƒ§ãƒ–ã®çŠ¶æ³ç¢ºèª
        ä½¿ç”¨ä¾‹: %colab_job_status job_1234567890
        """
        job_id = line.strip()
        if not job_id:
            # å…¨ã‚¸ãƒ§ãƒ–ã®çŠ¶æ³è¡¨ç¤º
            if not self.active_jobs:
                print("ğŸ“­ å®Ÿè¡Œä¸­ã®ã‚¸ãƒ§ãƒ–ã¯ã‚ã‚Šã¾ã›ã‚“")
                return
            
            print("ğŸ“Š å®Ÿè¡Œä¸­ã®ã‚¸ãƒ§ãƒ–:")
            for jid, job_info in self.active_jobs.items():
                elapsed = time.time() - job_info['start_time']
                print(f"  {jid}: {job_info['status']} ({elapsed:.0f}s)")
            return
        
        if job_id not in self.active_jobs:
            print(f"âŒ ã‚¸ãƒ§ãƒ– {job_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        job_info = self.active_jobs[job_id]
        print(f"ğŸ“Š Job Status: {job_id}")
        print("-" * 40)
        
        for node_id, url in job_info['nodes']:
            try:
                response = requests.get(f"{url}/job/{job_id}/status", timeout=5)
                status = response.json()
                
                print(f"Node {node_id}:")
                print(f"  Status: {status.get('status', 'unknown')}")
                print(f"  Epoch: {status.get('current_epoch', 0)}/{status.get('total_epochs', 0)}")
                print(f"  Loss: {status.get('current_loss', 'N/A')}")
                print()
                
            except Exception as e:
                print(f"Node {node_id}: âŒ ã‚¨ãƒ©ãƒ¼ - {str(e)}")
                print()
    
    # =========================================================================
    # HUGGINGFACE MAGIC COMMANDS
    # =========================================================================
    
    @line_magic
    def hf_login(self, line: str) -> None:
        """
        HuggingFace ã«ãƒ­ã‚°ã‚¤ãƒ³
        ä½¿ç”¨ä¾‹: %hf_login
        """
        try:
            from huggingface_hub import login, whoami
            
            if line.strip():
                # ãƒˆãƒ¼ã‚¯ãƒ³ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆ
                token = line.strip()
                login(token=token)
            else:
                # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ­ã‚°ã‚¤ãƒ³
                login()
            
            user_info = whoami()
            print(f"âœ… HuggingFace ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ: {user_info['name']}")
            
        except ImportError:
            print("âŒ huggingface_hub ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print("   pip install huggingface_hub")
        except Exception as e:
            print(f"âŒ ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—: {str(e)}")
    
    @line_magic
    def hf_push(self, line: str) -> None:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ HuggingFace Hub ã«ãƒ—ãƒƒã‚·ãƒ¥
        ä½¿ç”¨ä¾‹: %hf_push model_name --private
        """
        args = line.split()
        if not args:
            print("âŒ Usage: %hf_push <model_name> [--private]")
            return
        
        model_name = args[0]
        is_private = '--private' in args
        
        try:
            from huggingface_hub import HfApi, Repository
            
            api = HfApi()
            
            # ãƒ¢ãƒ‡ãƒ«ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ
            api.create_repo(
                repo_id=model_name,
                repo_type="model",
                private=is_private
            )
            
            print(f"ğŸ“¤ ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {model_name}")
            print(f"   ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ: {is_private}")
            
            # å®Ÿéš›ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¯è¦èª¿æ•´ï¼‰
            # api.upload_folder(folder_path="./model", repo_id=model_name)
            
            print(f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†!")
            print(f"   URL: https://huggingface.co/{model_name}")
            
        except ImportError:
            print("âŒ huggingface_hub ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        except Exception as e:
            print(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {str(e)}")
    
    @line_magic
    def hf_download(self, line: str) -> None:
        """
        HuggingFace Hub ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        ä½¿ç”¨ä¾‹: %hf_download bert-base-uncased
        """
        if not line.strip():
            print("âŒ Usage: %hf_download <model_name>")
            return
        
        model_name = line.strip()
        
        try:
            from transformers import AutoModel, AutoTokenizer
            
            print(f"ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {model_name}")
            
            # ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            model = AutoModel.from_pretrained(model_name)
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            
            print(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†!")
            print(f"   ãƒ¢ãƒ‡ãƒ«: {type(model).__name__}")
            print(f"   ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼: {type(tokenizer).__name__}")
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«è¨­å®š
            self.shell.user_ns['model'] = model
            self.shell.user_ns['tokenizer'] = tokenizer
            
        except ImportError:
            print("âŒ transformers ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print("   pip install transformers")
        except Exception as e:
            print(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {str(e)}")
    
    # =========================================================================
    # CLAUDE MAGIC COMMANDS  
    # =========================================================================
    
    @line_magic
    def claude(self, line: str) -> str:
        """
        Claude AI ã«è³ªå•
        ä½¿ç”¨ä¾‹: %claude "ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’æœ€é©åŒ–ã—ã¦"
        """
        if not line.strip():
            print("âŒ Usage: %claude \"<message>\"")
            return
        
        message = line.strip().strip('"\'')
        
        try:
            # Claude API å‘¼ã³å‡ºã—
            response = self._call_claude_api(message)
            
            print("ğŸ¤– Claude AI:")
            print("-" * 40)
            print(response)
            print("-" * 40)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã«è¿½åŠ 
            self.claude_session.append({'role': 'user', 'content': message})
            self.claude_session.append({'role': 'assistant', 'content': response})
            
            return response
            
        except Exception as e:
            print(f"âŒ Claude API ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return ""
    
    @cell_magic
    def claude_analyze(self, line: str, cell: str) -> str:
        """
        ã‚»ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã‚’ Claude AI ã§åˆ†æ
        ä½¿ç”¨ä¾‹:
        %%claude_analyze
        import pandas as pd
        df = pd.read_csv('data.csv')
        """
        analysis_prompt = f"""
ä»¥ä¸‹ã®Pythonã‚³ãƒ¼ãƒ‰ã‚’åˆ†æã—ã€æ”¹å–„ç‚¹ã‚’ææ¡ˆã—ã¦ãã ã•ã„:

```python
{cell}
```

ç‰¹ã«ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†æã—ã¦ãã ã•ã„:
1. ã‚³ãƒ¼ãƒ‰ã®åŠ¹ç‡æ€§
2. ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®é©ç”¨
3. æ½œåœ¨çš„ãªã‚¨ãƒ©ãƒ¼
4. æœ€é©åŒ–ã®ææ¡ˆ
"""
        
        try:
            response = self._call_claude_api(analysis_prompt)
            
            print("ğŸ” Claude ã‚³ãƒ¼ãƒ‰åˆ†æçµæœ:")
            print("=" * 50)
            print(response)
            print("=" * 50)
            
            return response
            
        except Exception as e:
            print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return ""
    
    @line_magic
    def claude_optimize(self, line: str) -> None:
        """
        ç›´å‰ã®ã‚»ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã‚’ Claude AI ã§æœ€é©åŒ–
        ä½¿ç”¨ä¾‹: %claude_optimize
        """
        # ç›´å‰ã®ã‚»ãƒ«ã®å†…å®¹ã‚’å–å¾—
        if hasattr(self.shell, 'history_manager'):
            history = self.shell.history_manager.get_range(-2, -1)
            if history:
                last_input = list(history)[0][2]  # (session, line_number, input)
                
                optimize_prompt = f"""
ä»¥ä¸‹ã®Pythonã‚³ãƒ¼ãƒ‰ã‚’æœ€é©åŒ–ã—ã¦ãã ã•ã„:

```python
{last_input}
```

æœ€é©åŒ–ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’æä¾›ã—ã€å¤‰æ›´ç‚¹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
"""
                
                try:
                    response = self._call_claude_api(optimize_prompt)
                    
                    print("âš¡ Claude æœ€é©åŒ–ææ¡ˆ:")
                    print("=" * 50)
                    print(response)
                    print("=" * 50)
                    
                except Exception as e:
                    print(f"âŒ æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            else:
                print("âŒ ç›´å‰ã®ã‚»ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            print("âŒ å±¥æ­´æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    # =========================================================================
    # UTILITY METHODS
    # =========================================================================
    
    def _parse_args(self, line: str) -> Dict[str, str]:
        """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’ãƒ‘ãƒ¼ã‚¹"""
        args = {}
        parts = line.split()
        
        i = 0
        while i < len(parts):
            if parts[i].startswith('--'):
                key = parts[i][2:]
                if i + 1 < len(parts) and not parts[i + 1].startswith('--'):
                    args[key] = parts[i + 1]
                    i += 2
                else:
                    args[key] = True
                    i += 1
            else:
                i += 1
        
        return args
    
    def _call_claude_api(self, message: str) -> str:
        """Claude API å‘¼ã³å‡ºã—"""
        try:
            # JupyterLab ExtensionçµŒç”±ã§Claude APIã‚’å‘¼ã³å‡ºã—
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ãªAPIå‘¼ã³å‡ºã—ã‚’è¡Œã†
            
            # æ¨¡æ“¬å¿œç­”ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯Claude APIã‚’ä½¿ç”¨ï¼‰
            responses = [
                "ã‚³ãƒ¼ãƒ‰ã‚’åˆ†æã—ã¾ã—ãŸã€‚ä»¥ä¸‹ã®æ”¹å–„ç‚¹ãŒã‚ã‚Šã¾ã™ï¼š\n1. å¤‰æ•°åã‚’ã‚ˆã‚Šæ˜ç¢ºã«\n2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®è¿½åŠ \n3. ã‚³ãƒ¡ãƒ³ãƒˆã®è¿½åŠ ",
                "ã“ã®ã‚³ãƒ¼ãƒ‰ã¯åŠ¹ç‡çš„ã§ã™ãŒã€ä»¥ä¸‹ã®æœ€é©åŒ–ãŒå¯èƒ½ã§ã™ï¼š\n1. ãƒªã‚¹ãƒˆå†…åŒ…è¡¨è¨˜ã®ä½¿ç”¨\n2. ä¸è¦ãªãƒ«ãƒ¼ãƒ—ã®å‰Šé™¤",
                "è‰¯ã„ã‚³ãƒ¼ãƒ‰ã§ã™ï¼ä»¥ä¸‹ã®ç‚¹ã§ã•ã‚‰ã«æ”¹å–„ã§ãã¾ã™ï¼š\n1. å‹ãƒ’ãƒ³ãƒˆã®è¿½åŠ \n2. docstringã®è¿½åŠ "
            ]
            
            import random
            return random.choice(responses)
            
        except Exception as e:
            raise Exception(f"Claude API call failed: {str(e)}")
    
    def _notify_extension(self, event: str, data: Dict[str, Any]) -> None:
        """JupyterLab Extension ã«é€šçŸ¥"""
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ Extension ã¨ã®é€šä¿¡ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½¿ç”¨
            print(f"ğŸ“¡ Extensioné€šçŸ¥: {event}")
            
        except Exception as e:
            print(f"âš ï¸  Extensioné€šçŸ¥å¤±æ•—: {str(e)}")


# Magic Commands ã‚’ IPython ã«ç™»éŒ²
def load_ipython_extension(ipython):
    """IPython Extension ã¨ã—ã¦ç™»éŒ²"""
    ipython.register_magic_function(AIDevMagics)
    print("ğŸš€ AI-Dev Magic Commands loaded!")
    print("Available commands:")
    print("  %colab_connect, %colab_status, %%colab_train")
    print("  %hf_login, %hf_push, %hf_download")
    print("  %claude, %%claude_analyze, %claude_optimize")


# =============================================================================
# COLAB API SERVER - Google Colab å´ã§å®Ÿè¡Œã™ã‚‹APIã‚µãƒ¼ãƒãƒ¼
# =============================================================================

"""
ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’Google Colabãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å®Ÿè¡Œã—ã¦ãã ã•ã„:

```python
# Colab ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ç”¨ API ã‚µãƒ¼ãƒãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

!pip install flask flask-cors pyngrok psutil py3nvml

import os
import json
import time
import threading
import psutil
import subprocess
from flask import Flask, request, jsonify
from flask_cors import CORS
from pyngrok import ngrok
import torch

# API ã‚µãƒ¼ãƒãƒ¼ä½œæˆ
app = Flask(__name__)
CORS(app)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
current_jobs = {}
system_info = {}

@app.route('/health')
def health_check():
    return jsonify({'status': 'healthy', 'timestamp': time.time()})

@app.route('/info')
def get_info():
    \"\"\"Colab ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æƒ…å ±\"\"\"
    try:
        # GPU æƒ…å ±
        gpu_info = "CPU only"
        if torch.cuda.is_available():
            gpu_info = torch.cuda.get_device_name(0)
        
        # Runtime æƒ…å ±
        runtime_info = {
            'gpu': gpu_info,
            'cuda_available': torch.cuda.is_available(),
            'torch_version': torch.__version__,
            'python_version': subprocess.check_output(['python', '--version']).decode().strip()
        }
        
        return jsonify(runtime_info)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/resources')
def get_resources():
    \"\"\"ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±\"\"\"
    try:
        resources = {
            'timestamp': time.time(),
            'cpu': {
                'count': psutil.cpu_count(),
                'usage': psutil.cpu_percent(interval=1)
            },
            'memory': {
                'total': psutil.virtual_memory().total,
                'used': psutil.virtual_memory().used,
                'percent': psutil.virtual_memory().percent
            },
            'disk': {
                'total': psutil.disk_usage('/').total,
                'used': psutil.disk_usage('/').used,
                'free': psutil.disk_usage('/').free
            },
            'gpu': []
        }
        
        # GPU æƒ…å ±
        if torch.cuda.is_available():
            for i in range(torch.cuda.device_count()):
                gpu_memory = torch.cuda.get_device_properties(i).total_memory
                gpu_memory_used = torch.cuda.memory_allocated(i)
                
                resources['gpu'].append({
                    'id': i,
                    'name': torch.cuda.get_device_name(i),
                    'memory_total': gpu_memory,
                    'memory_used': gpu_memory_used,
                    'memory_free': gpu_memory - gpu_memory_used,
                    'utilization': torch.cuda.utilization() if hasattr(torch.cuda, 'utilization') else 0,
                    'temperature': 0  # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ nvidia-ml-py ã‚’ä½¿ç”¨
                })
        
        return jsonify(resources)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/train', methods=['POST'])
def start_training():
    \"\"\"å­¦ç¿’ã‚¿ã‚¹ã‚¯ã®é–‹å§‹\"\"\"
    try:
        task_config = request.get_json()
        job_id = task_config['job_id']
        code = task_config['code']
        
        print(f"ğŸš€ å­¦ç¿’é–‹å§‹: Job {job_id}")
        
        # ã‚¸ãƒ§ãƒ–æƒ…å ±ã‚’ä¿å­˜
        current_jobs[job_id] = {
            'start_time': time.time(),
            'status': 'running',
            'config': task_config,
            'current_epoch': 0,
            'total_epochs': task_config.get('epochs', 10),
            'current_loss': None
        }
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
        thread = threading.Thread(target=execute_training_code, args=(job_id, code, task_config))
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'status': 'started',
            'job_id': job_id,
            'message': 'å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã—ãŸ'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/job/<job_id>/status')
def get_job_status(job_id):
    \"\"\"ã‚¸ãƒ§ãƒ–çŠ¶æ³ç¢ºèª\"\"\"
    if job_id not in current_jobs:
        return jsonify({'error': 'Job not found'}), 404
    
    job_info = current_jobs[job_id].copy()
    job_info['elapsed_time'] = time.time() - job_info['start_time']
    
    return jsonify(job_info)

@app.route('/shutdown', methods=['POST'])
def shutdown_server():
    \"\"\"ã‚µãƒ¼ãƒãƒ¼åœæ­¢\"\"\"
    print("ğŸ”Œ ã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¦ã„ã¾ã™...")
    return jsonify({'status': 'shutting down'})

def execute_training_code(job_id: str, code: str, config: dict):
    \"\"\"å­¦ç¿’ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œ\"\"\"
    try:
        print(f"ğŸ“Š Job {job_id}: ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œé–‹å§‹")
        
        # å®‰å…¨ãªã‚³ãƒ¼ãƒ‰å®Ÿè¡Œç’°å¢ƒ
        exec_globals = {
            '__builtins__': __builtins__,
            'torch': torch,
            'job_id': job_id,
            'config': config,
            'update_progress': lambda epoch, loss: update_job_progress(job_id, epoch, loss)
        }
        
        # ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ
        exec(code, exec_globals)
        
        # ã‚¸ãƒ§ãƒ–å®Œäº†
        current_jobs[job_id]['status'] = 'completed'
        current_jobs[job_id]['end_time'] = time.time()
        
        print(f"âœ… Job {job_id}: å®Ÿè¡Œå®Œäº†")
        
    except Exception as e:
        current_jobs[job_id]['status'] = 'error'
        current_jobs[job_id]['error'] = str(e)
        print(f"âŒ Job {job_id}: ã‚¨ãƒ©ãƒ¼ - {str(e)}")

def update_job_progress(job_id: str, epoch: int, loss: float):
    \"\"\"å­¦ç¿’é€²æ—ã®æ›´æ–°\"\"\"
    if job_id in current_jobs:
        current_jobs[job_id]['current_epoch'] = epoch
        current_jobs[job_id]['current_loss'] = loss
        print(f"ğŸ“ˆ Job {job_id}: Epoch {epoch}, Loss: {loss:.4f}")

# ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
def start_colab_server():
    print("ğŸš€ Colab API ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ã„ã¾ã™...")
    
    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§Flaskã‚µãƒ¼ãƒãƒ¼èµ·å‹•
    server_thread = threading.Thread(target=lambda: app.run(host='0.0.0.0', port=5000, debug=False))
    server_thread.daemon = True
    server_thread.start()
    
    time.sleep(2)  # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•å¾…æ©Ÿ
    
    # ngrok ã§ãƒˆãƒ³ãƒãƒ«é–‹è¨­
    tunnel = ngrok.connect(5000)
    public_url = tunnel.public_url
    
    print(f"âœ… ã‚µãƒ¼ãƒãƒ¼èµ·å‹•å®Œäº†!")
    print(f"ğŸ“¡ Public URL: {public_url}")
    print(f"ğŸ”— JupyterLabã§æ¥ç¶š: %colab_connect {public_url}")
    
    return public_url

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
if __name__ == "__main__":
    # ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’Colab ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å®Ÿè¡Œ
    url = start_colab_server()
```
"""